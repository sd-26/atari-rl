[32m[1214 20:06:48 @logger.py:92][0m Argv: ./DQN.py --env pong.bin
[32m[1214 20:06:48 @expreplay.py:41][0m Creating experience replay buffer of 6.6 GB ... use a smaller buffer if you don't have enough CPU memory.
[32m[1214 20:06:48 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[1214 20:06:48 @trainers.py:47][0m Building graph for a single training tower ...
[32m[1214 20:06:48 @registry.py:90][0m 'conv0': [?, 84, 84, 4] --> [?, 21, 21, 32]
[32m[1214 20:06:48 @registry.py:90][0m 'conv1': [?, 21, 21, 32] --> [?, 11, 11, 64]
[32m[1214 20:06:48 @registry.py:90][0m 'conv2': [?, 11, 11, 64] --> [?, 11, 11, 64]
[32m[1214 20:06:48 @registry.py:90][0m 'fc0': [?, 11, 11, 64] --> [?, 512]
[32m[1214 20:06:48 @registry.py:90][0m 'fct': [?, 512] --> [?, 6]
[32m[1214 20:06:48 @registry.py:90][0m 'target/conv0': [?, 84, 84, 4] --> [?, 21, 21, 32]
[32m[1214 20:06:48 @registry.py:90][0m 'target/conv1': [?, 21, 21, 32] --> [?, 11, 11, 64]
[32m[1214 20:06:48 @registry.py:90][0m 'target/conv2': [?, 11, 11, 64] --> [?, 11, 11, 64]
[32m[1214 20:06:48 @registry.py:90][0m 'target/fc0': [?, 11, 11, 64] --> [?, 512]
[32m[1214 20:06:48 @registry.py:90][0m 'target/fct': [?, 512] --> [?, 6]
[32m[1214 20:06:49 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname               shape             #elements
-----------------  --------------  -----------
conv0/W            [8, 8, 4, 32]          8192
conv0/b            [32]                     32
conv0/prelu/alpha  []                        1
conv1/W            [4, 4, 32, 64]        32768
conv1/b            [64]                     64
conv1/prelu/alpha  []                        1
conv2/W            [3, 3, 64, 64]        36864
conv2/b            [64]                     64
conv2/prelu/alpha  []                        1
fc0/W              [7744, 512]         3964928
fc0/b              [512]                   512
fct/W              [512, 6]               3072
fct/b              [6]                       6[36m
Number of trainable variables: 13
Number of parameters (elements): 4046505
Storage space needed for all trainable variables: 15.44MB[0m
[32m[1214 20:06:49 @base.py:207][0m Setup callbacks graph ...
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv0/W <- conv0/W
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv0/b <- conv0/b
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv0/prelu/alpha <- conv0/prelu/alpha
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv1/W <- conv1/W
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv1/b <- conv1/b
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv1/prelu/alpha <- conv1/prelu/alpha
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv2/W <- conv2/W
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv2/b <- conv2/b
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/conv2/prelu/alpha <- conv2/prelu/alpha
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/fc0/W <- fc0/W
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/fc0/b <- fc0/b
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/fct/W <- fct/W
[32m[1214 20:06:49 @DQNModel.py:117][0m Target Network Update: target/fct/b <- fct/b
[32m[1214 20:06:49 @tower.py:140][0m Building graph for predict tower 'tower-pred-0' on device /gpu:0 ...
[32m[1214 20:06:49 @summary.py:47][0m [MovingAverageSummary] 15 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[1214 20:06:49 @summary.py:94][0m Summarizing collection 'summaries' of size 40.
[32m[1214 20:06:49 @base.py:228][0m Creating the session ...
[32m[1214 20:07:00 @base.py:234][0m Initializing the session ...
[32m[1214 20:07:00 @base.py:241][0m Graph Finalized.
[32m[1214 20:07:00 @concurrency.py:37][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[1214 20:07:00 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:07:01 @expreplay.py:320][0m Populating replay memory with epsilon=1.0 ...
[32m[1214 20:07:19 @param.py:158][0m [HyperParamSetter] At global_step=0, learning_rate is set to 0.001000
[32m[1214 20:07:19 @param.py:158][0m [HyperParamSetter] At global_step=0, exploration is set to 1.000000
[32m[1214 20:07:19 @base.py:273][0m Start Epoch 1 ...
[32m[1214 20:07:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:08:35 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:09:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:09:47 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:10:23 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:10:23 @base.py:283][0m Epoch 1 (global_step 25000) finished, time:3 minutes 3 seconds.
[32m[1214 20:10:24 @saver.py:82][0m Model saved to train_log/DQN-pong/model-25000.
[32m[1214 20:10:24 @param.py:161][0m [HyperParamSetter] At global_step=25000, exploration changes from 1.000000 to 0.910000
[32m[1214 20:10:24 @monitor.py:474][0m QueueInput/queue_size: 6.7012
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 4.1245e-07
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 1.4795e-06
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 7.6387e-06
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 2.0805e-07
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 2.6276e-06
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 2.6175e-06
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 1.5877e-07
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 5.1663e-06
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 2.9987e-05
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 5.3592e-08
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 1.1913e-05
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/fct/W/rms: 1.4715e-06
[32m[1214 20:10:24 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0079175
[32m[1214 20:10:24 @monitor.py:474][0m expreplay/max_score: -17
[32m[1214 20:10:24 @monitor.py:474][0m expreplay/mean_score: -20.236
[32m[1214 20:10:24 @monitor.py:474][0m huber_loss/value: 0.013291
[32m[1214 20:10:24 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:10:24 @monitor.py:474][0m param-summary/conv0/W-rms: 0.087523
[32m[1214 20:10:24 @monitor.py:474][0m param-summary/conv1/W-rms: 0.062147
[32m[1214 20:10:24 @monitor.py:474][0m param-summary/conv2/W-rms: 0.058519
[32m[1214 20:10:24 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016077
[32m[1214 20:10:24 @monitor.py:474][0m param-summary/fct/W-rms: 0.059134
[32m[1214 20:10:24 @monitor.py:474][0m predict_reward: 0.28971
[32m[1214 20:10:24 @base.py:273][0m Start Epoch 2 ...
[32m[1214 20:11:00 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:11:37 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:12:14 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:12:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:13:27 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:13:27 @base.py:283][0m Epoch 2 (global_step 50000) finished, time:3 minutes 2 seconds.
[32m[1214 20:13:28 @saver.py:82][0m Model saved to train_log/DQN-pong/model-50000.
[32m[1214 20:13:28 @param.py:161][0m [HyperParamSetter] At global_step=50000, exploration changes from 0.910000 to 0.820000
[32m[1214 20:13:28 @monitor.py:474][0m QueueInput/queue_size: 0.47651
[32m[1214 20:13:28 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 1.4321e-07
[32m[1214 20:13:28 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 4.0673e-07
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 3.7753e-06
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 7.2892e-08
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 1.4783e-06
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 2.1396e-06
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 5.5315e-08
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 3.5973e-06
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 2.8241e-05
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.5481e-08
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 1.1728e-05
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/fct/W/rms: 1.3972e-06
[32m[1214 20:13:29 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.008215
[32m[1214 20:13:29 @monitor.py:474][0m expreplay/max_score: -17
[32m[1214 20:13:29 @monitor.py:474][0m expreplay/mean_score: -20.327
[32m[1214 20:13:29 @monitor.py:474][0m huber_loss/value: 0.01473
[32m[1214 20:13:29 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:13:29 @monitor.py:474][0m param-summary/conv0/W-rms: 0.087522
[32m[1214 20:13:29 @monitor.py:474][0m param-summary/conv1/W-rms: 0.062147
[32m[1214 20:13:29 @monitor.py:474][0m param-summary/conv2/W-rms: 0.058519
[32m[1214 20:13:29 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016077
[32m[1214 20:13:29 @monitor.py:474][0m param-summary/fct/W-rms: 0.059135
[32m[1214 20:13:29 @monitor.py:474][0m predict_reward: 0.17686
[32m[1214 20:13:29 @base.py:273][0m Start Epoch 3 ...
[32m[1214 20:14:05 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:14:42 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:15:19 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:15:57 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:16:34 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:16:34 @base.py:283][0m Epoch 3 (global_step 75000) finished, time:3 minutes 5 seconds.
[32m[1214 20:16:35 @saver.py:82][0m Model saved to train_log/DQN-pong/model-75000.
[32m[1214 20:16:35 @param.py:161][0m [HyperParamSetter] At global_step=75000, exploration changes from 0.820000 to 0.730000
[32m[1214 20:16:35 @monitor.py:474][0m QueueInput/queue_size: 0.39148
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 4.508e-07
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 1.1131e-06
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 1.4877e-05
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 1.8144e-07
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 3.9873e-06
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 3.2409e-06
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 1.3112e-07
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 7.5398e-06
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 2.7292e-05
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 6.7179e-08
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 2.2515e-05
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/fct/W/rms: 1.6098e-06
[32m[1214 20:16:35 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0066673
[32m[1214 20:16:35 @monitor.py:474][0m expreplay/max_score: -15
[32m[1214 20:16:35 @monitor.py:474][0m expreplay/mean_score: -20.093
[32m[1214 20:16:35 @monitor.py:474][0m huber_loss/value: 0.010791
[32m[1214 20:16:35 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:16:35 @monitor.py:474][0m param-summary/conv0/W-rms: 0.087523
[32m[1214 20:16:35 @monitor.py:474][0m param-summary/conv1/W-rms: 0.062147
[32m[1214 20:16:35 @monitor.py:474][0m param-summary/conv2/W-rms: 0.05852
[32m[1214 20:16:35 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016077
[32m[1214 20:16:35 @monitor.py:474][0m param-summary/fct/W-rms: 0.059138
[32m[1214 20:16:35 @monitor.py:474][0m predict_reward: 0.065776
[32m[1214 20:16:35 @base.py:273][0m Start Epoch 4 ...
[32m[1214 20:17:12 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:17:49 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:18:27 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:19:05 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:19:42 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:19:42 @base.py:283][0m Epoch 4 (global_step 100000) finished, time:3 minutes 7 seconds.
[32m[1214 20:19:43 @saver.py:82][0m Model saved to train_log/DQN-pong/model-100000.
[32m[1214 20:19:43 @param.py:161][0m [HyperParamSetter] At global_step=100000, exploration changes from 0.730000 to 0.640000
[32m[1214 20:19:43 @monitor.py:474][0m QueueInput/queue_size: 0.59546
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 9.2944e-07
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 1.9157e-06
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 1.3146e-05
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 2.8491e-07
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 7.5591e-06
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 8.4065e-06
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 2.1724e-07
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 1.6584e-05
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 2.1851e-05
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 1.3985e-07
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 4.9288e-05
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/fct/W/rms: 1.935e-06
[32m[1214 20:19:43 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0067408
[32m[1214 20:19:43 @monitor.py:474][0m expreplay/max_score: -17
[32m[1214 20:19:43 @monitor.py:474][0m expreplay/mean_score: -20.194
[32m[1214 20:19:43 @monitor.py:474][0m huber_loss/value: 0.010362
[32m[1214 20:19:43 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:19:43 @monitor.py:474][0m param-summary/conv0/W-rms: 0.087526
[32m[1214 20:19:43 @monitor.py:474][0m param-summary/conv1/W-rms: 0.062148
[32m[1214 20:19:43 @monitor.py:474][0m param-summary/conv2/W-rms: 0.05852
[32m[1214 20:19:43 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016077
[32m[1214 20:19:43 @monitor.py:474][0m param-summary/fct/W-rms: 0.059143
[32m[1214 20:19:43 @monitor.py:474][0m predict_reward: -0.038635
[32m[1214 20:19:43 @base.py:273][0m Start Epoch 5 ...
[32m[1214 20:20:21 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:20:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:21:37 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:22:15 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:22:54 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:22:54 @base.py:283][0m Epoch 5 (global_step 125000) finished, time:3 minutes 10 seconds.
[32m[1214 20:22:54 @saver.py:82][0m Model saved to train_log/DQN-pong/model-125000.
[32m[1214 20:22:54 @param.py:161][0m [HyperParamSetter] At global_step=125000, exploration changes from 0.640000 to 0.550000
[32m[1214 20:23:29 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 20:23:29 @monitor.py:474][0m QueueInput/queue_size: 0.18745
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 1.0492e-05
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 2.0967e-05
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.00021185
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 2.3241e-06
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 5.3159e-05
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 5.944e-05
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 1.5969e-06
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.000105
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.00017805
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 6.4951e-07
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00016294
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/fct/W/rms: 6.1011e-06
[32m[1214 20:23:29 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0083261
[32m[1214 20:23:29 @monitor.py:474][0m expreplay/max_score: -17
[32m[1214 20:23:29 @monitor.py:474][0m expreplay/mean_score: -20.436
[32m[1214 20:23:29 @monitor.py:474][0m huber_loss/value: 0.014092
[32m[1214 20:23:29 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:23:29 @monitor.py:474][0m max_score: -21
[32m[1214 20:23:29 @monitor.py:474][0m mean_score: -21
[32m[1214 20:23:29 @monitor.py:474][0m param-summary/conv0/W-rms: 0.087538
[32m[1214 20:23:29 @monitor.py:474][0m param-summary/conv1/W-rms: 0.062152
[32m[1214 20:23:29 @monitor.py:474][0m param-summary/conv2/W-rms: 0.058525
[32m[1214 20:23:29 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016077
[32m[1214 20:23:29 @monitor.py:474][0m param-summary/fct/W-rms: 0.059191
[32m[1214 20:23:29 @monitor.py:474][0m predict_reward: -0.1538
[32m[1214 20:23:29 @group.py:44][0m Callbacks took 35.125 sec in total. PeriodicTrigger-Evaluator: 34.4 seconds
[32m[1214 20:23:29 @base.py:273][0m Start Epoch 6 ...
[32m[1214 20:24:08 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:24:46 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:25:25 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:26:04 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:26:43 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:26:43 @base.py:283][0m Epoch 6 (global_step 150000) finished, time:3 minutes 13 seconds.
[32m[1214 20:26:43 @saver.py:82][0m Model saved to train_log/DQN-pong/model-150000.
[32m[1214 20:26:43 @param.py:161][0m [HyperParamSetter] At global_step=150000, exploration changes from 0.550000 to 0.460000
[32m[1214 20:26:43 @monitor.py:474][0m QueueInput/queue_size: 0.65538
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00046241
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0011611
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0023823
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00026154
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.001367
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0023259
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00019265
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0016655
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0013648
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.4435e-05
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00050051
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00032742
[32m[1214 20:26:43 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0035998
[32m[1214 20:26:43 @monitor.py:474][0m expreplay/max_score: -17
[32m[1214 20:26:43 @monitor.py:474][0m expreplay/mean_score: -20.198
[32m[1214 20:26:43 @monitor.py:474][0m huber_loss/value: 0.0019015
[32m[1214 20:26:43 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:26:43 @monitor.py:474][0m param-summary/conv0/W-rms: 0.09049
[32m[1214 20:26:43 @monitor.py:474][0m param-summary/conv1/W-rms: 0.063137
[32m[1214 20:26:43 @monitor.py:474][0m param-summary/conv2/W-rms: 0.059386
[32m[1214 20:26:43 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016112
[32m[1214 20:26:43 @monitor.py:474][0m param-summary/fct/W-rms: 0.068461
[32m[1214 20:26:43 @monitor.py:474][0m predict_reward: -0.20772
[32m[1214 20:26:43 @base.py:273][0m Start Epoch 7 ...
[32m[1214 20:27:22 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:28:01 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:28:41 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:29:20 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:29:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:29:59 @base.py:283][0m Epoch 7 (global_step 175000) finished, time:3 minutes 15 seconds.
[32m[1214 20:30:00 @saver.py:82][0m Model saved to train_log/DQN-pong/model-175000.
[32m[1214 20:30:00 @param.py:161][0m [HyperParamSetter] At global_step=175000, exploration changes from 0.460000 to 0.370000
[32m[1214 20:30:00 @monitor.py:474][0m QueueInput/queue_size: 0.25305
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00072363
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0018636
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0035712
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00027168
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0016079
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0028142
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00020926
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0026021
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0017028
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.9558e-05
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00050017
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00025334
[32m[1214 20:30:00 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0034262
[32m[1214 20:30:00 @monitor.py:474][0m expreplay/max_score: -18
[32m[1214 20:30:00 @monitor.py:474][0m expreplay/mean_score: -20.396
[32m[1214 20:30:00 @monitor.py:474][0m huber_loss/value: 0.0022502
[32m[1214 20:30:00 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:30:00 @monitor.py:474][0m param-summary/conv0/W-rms: 0.095272
[32m[1214 20:30:00 @monitor.py:474][0m param-summary/conv1/W-rms: 0.064217
[32m[1214 20:30:00 @monitor.py:474][0m param-summary/conv2/W-rms: 0.060064
[32m[1214 20:30:00 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016138
[32m[1214 20:30:00 @monitor.py:474][0m param-summary/fct/W-rms: 0.071789
[32m[1214 20:30:00 @monitor.py:474][0m predict_reward: -0.25564
[32m[1214 20:30:00 @base.py:273][0m Start Epoch 8 ...
[32m[1214 20:30:39 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:31:19 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:31:58 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:32:38 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:33:18 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:33:18 @base.py:283][0m Epoch 8 (global_step 200000) finished, time:3 minutes 18 seconds.
[32m[1214 20:33:18 @saver.py:82][0m Model saved to train_log/DQN-pong/model-200000.
[32m[1214 20:33:18 @param.py:161][0m [HyperParamSetter] At global_step=200000, exploration changes from 0.370000 to 0.280000
[32m[1214 20:33:18 @monitor.py:474][0m QueueInput/queue_size: 0.73552
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00064895
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0015719
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0030453
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00026825
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0015773
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0070211
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00027034
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0029929
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.001264
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.7213e-05
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00064208
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00024904
[32m[1214 20:33:18 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0035984
[32m[1214 20:33:18 @monitor.py:474][0m expreplay/max_score: -16
[32m[1214 20:33:18 @monitor.py:474][0m expreplay/mean_score: -20.192
[32m[1214 20:33:18 @monitor.py:474][0m huber_loss/value: 0.0018584
[32m[1214 20:33:18 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:33:18 @monitor.py:474][0m param-summary/conv0/W-rms: 0.099316
[32m[1214 20:33:18 @monitor.py:474][0m param-summary/conv1/W-rms: 0.064971
[32m[1214 20:33:18 @monitor.py:474][0m param-summary/conv2/W-rms: 0.060528
[32m[1214 20:33:18 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016155
[32m[1214 20:33:18 @monitor.py:474][0m param-summary/fct/W-rms: 0.072348
[32m[1214 20:33:18 @monitor.py:474][0m predict_reward: -0.39229
[32m[1214 20:33:18 @base.py:273][0m Start Epoch 9 ...
[32m[1214 20:33:58 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:34:38 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:35:18 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:35:58 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:36:38 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:36:38 @base.py:283][0m Epoch 9 (global_step 225000) finished, time:3 minutes 19 seconds.
[32m[1214 20:36:39 @saver.py:82][0m Model saved to train_log/DQN-pong/model-225000.
[32m[1214 20:36:39 @param.py:161][0m [HyperParamSetter] At global_step=225000, exploration changes from 0.280000 to 0.190000
[32m[1214 20:36:39 @monitor.py:474][0m QueueInput/queue_size: 0.031176
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.0005873
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0014427
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0027159
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00020641
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.001144
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0029211
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00019763
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0022485
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0016015
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.5542e-05
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00037407
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00022534
[32m[1214 20:36:39 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0032098
[32m[1214 20:36:39 @monitor.py:474][0m expreplay/max_score: -17
[32m[1214 20:36:39 @monitor.py:474][0m expreplay/mean_score: -19.773
[32m[1214 20:36:39 @monitor.py:474][0m huber_loss/value: 0.00219
[32m[1214 20:36:39 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:36:39 @monitor.py:474][0m param-summary/conv0/W-rms: 0.10185
[32m[1214 20:36:39 @monitor.py:474][0m param-summary/conv1/W-rms: 0.065471
[32m[1214 20:36:39 @monitor.py:474][0m param-summary/conv2/W-rms: 0.060893
[32m[1214 20:36:39 @monitor.py:474][0m param-summary/fc0/W-rms: 0.01617
[32m[1214 20:36:39 @monitor.py:474][0m param-summary/fct/W-rms: 0.072964
[32m[1214 20:36:39 @monitor.py:474][0m predict_reward: -0.48161
[32m[1214 20:36:39 @base.py:273][0m Start Epoch 10 ...
[32m[1214 20:37:19 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:37:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:38:39 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:39:19 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:40:00 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:40:00 @base.py:283][0m Epoch 10 (global_step 250000) finished, time:3 minutes 20 seconds.
[32m[1214 20:40:00 @saver.py:82][0m Model saved to train_log/DQN-pong/model-250000.
[32m[1214 20:40:00 @param.py:161][0m [HyperParamSetter] At global_step=250000, exploration changes from 0.190000 to 0.100000
[32m[1214 20:40:38 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 20:40:38 @monitor.py:474][0m QueueInput/queue_size: 0.032958
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00084031
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0020718
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0030626
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00027018
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0014908
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0051689
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.0003348
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0035469
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0020389
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.7469e-05
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00072498
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00037304
[32m[1214 20:40:38 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0055704
[32m[1214 20:40:38 @monitor.py:474][0m expreplay/max_score: -16
[32m[1214 20:40:38 @monitor.py:474][0m expreplay/mean_score: -19.506
[32m[1214 20:40:38 @monitor.py:474][0m huber_loss/value: 0.0036044
[32m[1214 20:40:38 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:40:38 @monitor.py:474][0m max_score: -20
[32m[1214 20:40:38 @monitor.py:474][0m mean_score: -20.72
[32m[1214 20:40:38 @monitor.py:474][0m param-summary/conv0/W-rms: 0.1051
[32m[1214 20:40:38 @monitor.py:474][0m param-summary/conv1/W-rms: 0.066076
[32m[1214 20:40:38 @monitor.py:474][0m param-summary/conv2/W-rms: 0.061403
[32m[1214 20:40:38 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016192
[32m[1214 20:40:38 @monitor.py:474][0m param-summary/fct/W-rms: 0.073029
[32m[1214 20:40:38 @monitor.py:474][0m predict_reward: -0.49411
[32m[1214 20:40:38 @group.py:44][0m Callbacks took 38.392 sec in total. PeriodicTrigger-Evaluator: 37.7 seconds
[32m[1214 20:40:38 @base.py:273][0m Start Epoch 11 ...
[32m[1214 20:41:18 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:41:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:42:39 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:43:20 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:44:00 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:44:00 @base.py:283][0m Epoch 11 (global_step 275000) finished, time:3 minutes 22 seconds.
[32m[1214 20:44:01 @saver.py:82][0m Model saved to train_log/DQN-pong/model-275000.
[32m[1214 20:44:01 @param.py:161][0m [HyperParamSetter] At global_step=275000, exploration changes from 0.100000 to 0.099769
[32m[1214 20:44:01 @monitor.py:474][0m QueueInput/queue_size: 0.25583
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00062013
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0015533
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0024362
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00020587
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0010892
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0060302
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00026703
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0027853
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0013473
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.5907e-05
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00050434
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00027124
[32m[1214 20:44:01 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0039685
[32m[1214 20:44:01 @monitor.py:474][0m expreplay/max_score: -14
[32m[1214 20:44:01 @monitor.py:474][0m expreplay/mean_score: -18.143
[32m[1214 20:44:01 @monitor.py:474][0m huber_loss/value: 0.0023537
[32m[1214 20:44:01 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:44:01 @monitor.py:474][0m param-summary/conv0/W-rms: 0.1077
[32m[1214 20:44:01 @monitor.py:474][0m param-summary/conv1/W-rms: 0.066579
[32m[1214 20:44:01 @monitor.py:474][0m param-summary/conv2/W-rms: 0.061857
[32m[1214 20:44:01 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016211
[32m[1214 20:44:01 @monitor.py:474][0m param-summary/fct/W-rms: 0.072793
[32m[1214 20:44:01 @monitor.py:474][0m predict_reward: -0.52786
[32m[1214 20:44:01 @base.py:273][0m Start Epoch 12 ...
[32m[1214 20:44:41 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:45:21 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:46:02 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:46:43 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:47:23 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:47:23 @base.py:283][0m Epoch 12 (global_step 300000) finished, time:3 minutes 22 seconds.
[32m[1214 20:47:24 @saver.py:82][0m Model saved to train_log/DQN-pong/model-300000.
[32m[1214 20:47:24 @param.py:161][0m [HyperParamSetter] At global_step=300000, exploration changes from 0.099769 to 0.099538
[32m[1214 20:47:24 @monitor.py:474][0m QueueInput/queue_size: 0.49999
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00071504
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0017842
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0024373
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00024364
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0013171
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0044927
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00024542
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0028159
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.001213
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.199e-05
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00040961
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00026927
[32m[1214 20:47:24 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0037818
[32m[1214 20:47:24 @monitor.py:474][0m expreplay/max_score: -14
[32m[1214 20:47:24 @monitor.py:474][0m expreplay/mean_score: -18.315
[32m[1214 20:47:24 @monitor.py:474][0m huber_loss/value: 0.0025489
[32m[1214 20:47:24 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:47:24 @monitor.py:474][0m param-summary/conv0/W-rms: 0.11049
[32m[1214 20:47:24 @monitor.py:474][0m param-summary/conv1/W-rms: 0.067144
[32m[1214 20:47:24 @monitor.py:474][0m param-summary/conv2/W-rms: 0.062363
[32m[1214 20:47:24 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016233
[32m[1214 20:47:24 @monitor.py:474][0m param-summary/fct/W-rms: 0.073109
[32m[1214 20:47:24 @monitor.py:474][0m predict_reward: -0.52946
[32m[1214 20:47:24 @base.py:273][0m Start Epoch 13 ...
[32m[1214 20:48:04 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:48:45 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:49:25 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:50:06 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:50:46 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:50:46 @base.py:283][0m Epoch 13 (global_step 325000) finished, time:3 minutes 21 seconds.
[32m[1214 20:50:47 @saver.py:82][0m Model saved to train_log/DQN-pong/model-325000.
[32m[1214 20:50:47 @param.py:161][0m [HyperParamSetter] At global_step=325000, exploration changes from 0.099538 to 0.099308
[32m[1214 20:50:47 @monitor.py:474][0m QueueInput/queue_size: 0.48804
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00081867
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0020537
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0026353
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00030418
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0015206
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0053589
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.0003923
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0035165
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.001936
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 5.4169e-05
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00069133
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00040521
[32m[1214 20:50:47 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0051818
[32m[1214 20:50:47 @monitor.py:474][0m expreplay/max_score: -9
[32m[1214 20:50:47 @monitor.py:474][0m expreplay/mean_score: -16.02
[32m[1214 20:50:47 @monitor.py:474][0m huber_loss/value: 0.0029564
[32m[1214 20:50:47 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:50:47 @monitor.py:474][0m param-summary/conv0/W-rms: 0.11363
[32m[1214 20:50:47 @monitor.py:474][0m param-summary/conv1/W-rms: 0.067781
[32m[1214 20:50:47 @monitor.py:474][0m param-summary/conv2/W-rms: 0.062902
[32m[1214 20:50:47 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016259
[32m[1214 20:50:47 @monitor.py:474][0m param-summary/fct/W-rms: 0.073395
[32m[1214 20:50:47 @monitor.py:474][0m predict_reward: -0.56141
[32m[1214 20:50:47 @base.py:273][0m Start Epoch 14 ...
[32m[1214 20:51:27 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:52:07 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:52:48 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:53:28 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:54:09 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:54:09 @base.py:283][0m Epoch 14 (global_step 350000) finished, time:3 minutes 22 seconds.
[32m[1214 20:54:10 @saver.py:82][0m Model saved to train_log/DQN-pong/model-350000.
[32m[1214 20:54:10 @param.py:161][0m [HyperParamSetter] At global_step=350000, exploration changes from 0.099308 to 0.099077
[32m[1214 20:54:10 @monitor.py:474][0m QueueInput/queue_size: 0.40574
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00087839
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0021407
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0031724
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.0003101
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0013957
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0039948
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00030699
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0031073
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0015754
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.4839e-05
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00046346
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00041158
[32m[1214 20:54:10 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.004999
[32m[1214 20:54:10 @monitor.py:474][0m expreplay/max_score: -4
[32m[1214 20:54:10 @monitor.py:474][0m expreplay/mean_score: -15.373
[32m[1214 20:54:10 @monitor.py:474][0m huber_loss/value: 0.004138
[32m[1214 20:54:10 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:54:10 @monitor.py:474][0m param-summary/conv0/W-rms: 0.11809
[32m[1214 20:54:10 @monitor.py:474][0m param-summary/conv1/W-rms: 0.068742
[32m[1214 20:54:10 @monitor.py:474][0m param-summary/conv2/W-rms: 0.063642
[32m[1214 20:54:10 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016298
[32m[1214 20:54:10 @monitor.py:474][0m param-summary/fct/W-rms: 0.074056
[32m[1214 20:54:10 @monitor.py:474][0m predict_reward: -0.54891
[32m[1214 20:54:10 @base.py:273][0m Start Epoch 15 ...
[32m[1214 20:54:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:55:30 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:56:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:56:52 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:57:32 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 20:57:32 @base.py:283][0m Epoch 15 (global_step 375000) finished, time:3 minutes 22 seconds.
[32m[1214 20:57:33 @saver.py:82][0m Model saved to train_log/DQN-pong/model-375000.
[32m[1214 20:57:33 @param.py:161][0m [HyperParamSetter] At global_step=375000, exploration changes from 0.099077 to 0.098846
[32m[1214 20:58:45 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 20:58:45 @monitor.py:474][0m QueueInput/queue_size: 0.49222
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00094669
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0023744
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0033851
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00031672
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.001382
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0057175
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00028982
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0029986
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0016218
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.4476e-05
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00041951
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00043267
[32m[1214 20:58:45 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0050408
[32m[1214 20:58:45 @monitor.py:474][0m expreplay/max_score: -5
[32m[1214 20:58:45 @monitor.py:474][0m expreplay/mean_score: -14.75
[32m[1214 20:58:45 @monitor.py:474][0m huber_loss/value: 0.003825
[32m[1214 20:58:45 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 20:58:45 @monitor.py:474][0m max_score: -11
[32m[1214 20:58:45 @monitor.py:474][0m mean_score: -16.76
[32m[1214 20:58:45 @monitor.py:474][0m param-summary/conv0/W-rms: 0.12213
[32m[1214 20:58:45 @monitor.py:474][0m param-summary/conv1/W-rms: 0.069634
[32m[1214 20:58:45 @monitor.py:474][0m param-summary/conv2/W-rms: 0.064298
[32m[1214 20:58:45 @monitor.py:474][0m param-summary/fc0/W-rms: 0.01634
[32m[1214 20:58:45 @monitor.py:474][0m param-summary/fct/W-rms: 0.07472
[32m[1214 20:58:45 @monitor.py:474][0m predict_reward: -0.49866
[32m[1214 20:58:45 @group.py:44][0m Callbacks took 72.862 sec in total. PeriodicTrigger-Evaluator: 1 minute 12 seconds
[32m[1214 20:58:45 @base.py:273][0m Start Epoch 16 ...
[32m[1214 20:59:25 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:00:06 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:00:46 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:01:27 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:02:07 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:02:07 @base.py:283][0m Epoch 16 (global_step 400000) finished, time:3 minutes 22 seconds.
[32m[1214 21:02:08 @saver.py:82][0m Model saved to train_log/DQN-pong/model-400000.
[32m[1214 21:02:08 @param.py:161][0m [HyperParamSetter] At global_step=400000, exploration changes from 0.098846 to 0.098615
[32m[1214 21:02:08 @monitor.py:474][0m QueueInput/queue_size: 1.3731
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.0010666
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0026018
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0051984
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00037853
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0016549
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0072882
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00033267
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0037037
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0021301
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 5.2811e-05
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00045531
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00048903
[32m[1214 21:02:08 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0056227
[32m[1214 21:02:08 @monitor.py:474][0m expreplay/max_score: -3
[32m[1214 21:02:08 @monitor.py:474][0m expreplay/mean_score: -13.426
[32m[1214 21:02:08 @monitor.py:474][0m huber_loss/value: 0.0045256
[32m[1214 21:02:08 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:02:08 @monitor.py:474][0m param-summary/conv0/W-rms: 0.12597
[32m[1214 21:02:08 @monitor.py:474][0m param-summary/conv1/W-rms: 0.070556
[32m[1214 21:02:08 @monitor.py:474][0m param-summary/conv2/W-rms: 0.064962
[32m[1214 21:02:08 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016391
[32m[1214 21:02:08 @monitor.py:474][0m param-summary/fct/W-rms: 0.075821
[32m[1214 21:02:08 @monitor.py:474][0m predict_reward: -0.44017
[32m[1214 21:02:08 @base.py:273][0m Start Epoch 17 ...
[32m[1214 21:02:48 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:03:29 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:04:09 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:04:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:05:31 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:05:31 @base.py:283][0m Epoch 17 (global_step 425000) finished, time:3 minutes 22 seconds.
[32m[1214 21:05:31 @saver.py:82][0m Model saved to train_log/DQN-pong/model-425000.
[32m[1214 21:05:31 @param.py:161][0m [HyperParamSetter] At global_step=425000, exploration changes from 0.098615 to 0.098385
[32m[1214 21:05:31 @monitor.py:474][0m QueueInput/queue_size: 0.49313
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00079928
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0019499
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0032273
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00030307
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0012534
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0066532
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00027714
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0029902
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0020586
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.566e-05
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00036129
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00043894
[32m[1214 21:05:31 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0048831
[32m[1214 21:05:31 @monitor.py:474][0m expreplay/max_score: -2
[32m[1214 21:05:31 @monitor.py:474][0m expreplay/mean_score: -12.409
[32m[1214 21:05:31 @monitor.py:474][0m huber_loss/value: 0.003981
[32m[1214 21:05:31 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:05:31 @monitor.py:474][0m param-summary/conv0/W-rms: 0.12933
[32m[1214 21:05:31 @monitor.py:474][0m param-summary/conv1/W-rms: 0.071393
[32m[1214 21:05:31 @monitor.py:474][0m param-summary/conv2/W-rms: 0.065546
[32m[1214 21:05:31 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016441
[32m[1214 21:05:31 @monitor.py:474][0m param-summary/fct/W-rms: 0.076693
[32m[1214 21:05:31 @monitor.py:474][0m predict_reward: -0.40417
[32m[1214 21:05:31 @base.py:273][0m Start Epoch 18 ...
[32m[1214 21:06:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:06:52 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:07:32 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:08:13 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:08:54 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:08:54 @base.py:283][0m Epoch 18 (global_step 450000) finished, time:3 minutes 22 seconds.
[32m[1214 21:08:55 @saver.py:82][0m Model saved to train_log/DQN-pong/model-450000.
[32m[1214 21:08:55 @param.py:161][0m [HyperParamSetter] At global_step=450000, exploration changes from 0.098385 to 0.098154
[32m[1214 21:08:55 @monitor.py:474][0m QueueInput/queue_size: 0.49218
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00075549
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0018651
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0029487
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.0002551
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0010663
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0044695
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.0002136
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0024229
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0018542
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.6147e-05
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00027471
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00040262
[32m[1214 21:08:55 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0044259
[32m[1214 21:08:55 @monitor.py:474][0m expreplay/max_score: 1
[32m[1214 21:08:55 @monitor.py:474][0m expreplay/mean_score: -10.4
[32m[1214 21:08:55 @monitor.py:474][0m huber_loss/value: 0.0035562
[32m[1214 21:08:55 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:08:55 @monitor.py:474][0m param-summary/conv0/W-rms: 0.13231
[32m[1214 21:08:55 @monitor.py:474][0m param-summary/conv1/W-rms: 0.072151
[32m[1214 21:08:55 @monitor.py:474][0m param-summary/conv2/W-rms: 0.066055
[32m[1214 21:08:55 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016487
[32m[1214 21:08:55 @monitor.py:474][0m param-summary/fct/W-rms: 0.077214
[32m[1214 21:08:55 @monitor.py:474][0m predict_reward: -0.37498
[32m[1214 21:08:55 @base.py:273][0m Start Epoch 19 ...
[32m[1214 21:09:35 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:10:15 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:10:56 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:11:36 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:12:17 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:12:17 @base.py:283][0m Epoch 19 (global_step 475000) finished, time:3 minutes 22 seconds.
[32m[1214 21:12:18 @saver.py:82][0m Model saved to train_log/DQN-pong/model-475000.
[32m[1214 21:12:18 @param.py:161][0m [HyperParamSetter] At global_step=475000, exploration changes from 0.098154 to 0.097923
[32m[1214 21:12:18 @monitor.py:474][0m QueueInput/queue_size: 0.095436
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00081358
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.001987
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0033855
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00030243
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0011942
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0038732
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00025104
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0025205
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.001666
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.3557e-05
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00027057
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00041785
[32m[1214 21:12:18 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0044083
[32m[1214 21:12:18 @monitor.py:474][0m expreplay/max_score: 6
[32m[1214 21:12:18 @monitor.py:474][0m expreplay/mean_score: -6.0833
[32m[1214 21:12:18 @monitor.py:474][0m huber_loss/value: 0.0036268
[32m[1214 21:12:18 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:12:18 @monitor.py:474][0m param-summary/conv0/W-rms: 0.13552
[32m[1214 21:12:18 @monitor.py:474][0m param-summary/conv1/W-rms: 0.072991
[32m[1214 21:12:18 @monitor.py:474][0m param-summary/conv2/W-rms: 0.066635
[32m[1214 21:12:18 @monitor.py:474][0m param-summary/fc0/W-rms: 0.01654
[32m[1214 21:12:18 @monitor.py:474][0m param-summary/fct/W-rms: 0.078139
[32m[1214 21:12:18 @monitor.py:474][0m predict_reward: -0.32049
[32m[1214 21:12:18 @base.py:273][0m Start Epoch 20 ...
[32m[1214 21:12:58 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:13:39 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:14:19 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:15:00 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:15:41 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:15:41 @base.py:283][0m Epoch 20 (global_step 500000) finished, time:3 minutes 22 seconds.
[32m[1214 21:15:41 @saver.py:82][0m Model saved to train_log/DQN-pong/model-500000.
[32m[1214 21:15:41 @param.py:161][0m [HyperParamSetter] At global_step=500000, exploration changes from 0.097923 to 0.097692
[32m[1214 21:18:08 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 21:18:08 @monitor.py:474][0m QueueInput/queue_size: 1.5006
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00078246
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0019507
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0039507
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.0003007
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0011984
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0043179
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00024613
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0025026
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0022383
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.3326e-05
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00028484
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00044434
[32m[1214 21:18:08 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.004711
[32m[1214 21:18:08 @monitor.py:474][0m expreplay/max_score: 8
[32m[1214 21:18:08 @monitor.py:474][0m expreplay/mean_score: -3.6452
[32m[1214 21:18:08 @monitor.py:474][0m huber_loss/value: 0.0043117
[32m[1214 21:18:08 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:18:08 @monitor.py:474][0m max_score: 17
[32m[1214 21:18:08 @monitor.py:474][0m mean_score: -0.4
[32m[1214 21:18:08 @monitor.py:474][0m param-summary/conv0/W-rms: 0.13836
[32m[1214 21:18:08 @monitor.py:474][0m param-summary/conv1/W-rms: 0.073736
[32m[1214 21:18:08 @monitor.py:474][0m param-summary/conv2/W-rms: 0.067128
[32m[1214 21:18:08 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016595
[32m[1214 21:18:08 @monitor.py:474][0m param-summary/fct/W-rms: 0.078328
[32m[1214 21:18:08 @monitor.py:474][0m predict_reward: -0.27168
[32m[1214 21:18:08 @group.py:44][0m Callbacks took 147.767 sec in total. PeriodicTrigger-Evaluator: 2 minutes 27 seconds
[32m[1214 21:18:08 @base.py:273][0m Start Epoch 21 ...
[32m[1214 21:18:49 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:19:29 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:20:09 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:20:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:21:30 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:21:30 @base.py:283][0m Epoch 21 (global_step 525000) finished, time:3 minutes 21 seconds.
[32m[1214 21:21:31 @saver.py:82][0m Model saved to train_log/DQN-pong/model-525000.
[32m[1214 21:21:31 @param.py:161][0m [HyperParamSetter] At global_step=525000, exploration changes from 0.097692 to 0.097462
[32m[1214 21:21:31 @monitor.py:474][0m QueueInput/queue_size: 0.87683
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.0007967
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0019742
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0031641
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00032432
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0012218
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0064473
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00024767
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0026149
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0029139
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.5482e-05
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00028954
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00048112
[32m[1214 21:21:31 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0051541
[32m[1214 21:21:31 @monitor.py:474][0m expreplay/max_score: 9
[32m[1214 21:21:31 @monitor.py:474][0m expreplay/mean_score: -3.6562
[32m[1214 21:21:31 @monitor.py:474][0m huber_loss/value: 0.0042081
[32m[1214 21:21:31 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:21:31 @monitor.py:474][0m param-summary/conv0/W-rms: 0.14127
[32m[1214 21:21:31 @monitor.py:474][0m param-summary/conv1/W-rms: 0.074551
[32m[1214 21:21:31 @monitor.py:474][0m param-summary/conv2/W-rms: 0.06766
[32m[1214 21:21:31 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016655
[32m[1214 21:21:31 @monitor.py:474][0m param-summary/fct/W-rms: 0.079325
[32m[1214 21:21:31 @monitor.py:474][0m predict_reward: -0.28259
[32m[1214 21:21:31 @base.py:273][0m Start Epoch 22 ...
[32m[1214 21:22:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:22:51 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:23:32 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:24:13 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:24:54 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:24:54 @base.py:283][0m Epoch 22 (global_step 550000) finished, time:3 minutes 22 seconds.
[32m[1214 21:24:54 @saver.py:82][0m Model saved to train_log/DQN-pong/model-550000.
[32m[1214 21:24:54 @param.py:161][0m [HyperParamSetter] At global_step=550000, exploration changes from 0.097462 to 0.097231
[32m[1214 21:24:54 @monitor.py:474][0m QueueInput/queue_size: 0.40715
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.0007113
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0018066
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0041863
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00027987
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0010585
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.004794
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00022155
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0022938
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0018756
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.2269e-05
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00024184
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00049458
[32m[1214 21:24:54 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0048896
[32m[1214 21:24:54 @monitor.py:474][0m expreplay/max_score: 12
[32m[1214 21:24:54 @monitor.py:474][0m expreplay/mean_score: -0.39394
[32m[1214 21:24:54 @monitor.py:474][0m huber_loss/value: 0.0047515
[32m[1214 21:24:54 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:24:54 @monitor.py:474][0m param-summary/conv0/W-rms: 0.14399
[32m[1214 21:24:54 @monitor.py:474][0m param-summary/conv1/W-rms: 0.07533
[32m[1214 21:24:54 @monitor.py:474][0m param-summary/conv2/W-rms: 0.068117
[32m[1214 21:24:54 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016719
[32m[1214 21:24:54 @monitor.py:474][0m param-summary/fct/W-rms: 0.079881
[32m[1214 21:24:54 @monitor.py:474][0m predict_reward: -0.24301
[32m[1214 21:24:54 @base.py:273][0m Start Epoch 23 ...
[32m[1214 21:25:34 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:26:15 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:26:55 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:27:36 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:28:16 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:28:16 @base.py:283][0m Epoch 23 (global_step 575000) finished, time:3 minutes 21 seconds.
[32m[1214 21:28:17 @saver.py:82][0m Model saved to train_log/DQN-pong/model-575000.
[32m[1214 21:28:17 @param.py:161][0m [HyperParamSetter] At global_step=575000, exploration changes from 0.097231 to 0.097000
[32m[1214 21:28:17 @monitor.py:474][0m QueueInput/queue_size: 0.49998
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00059134
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0014776
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0037075
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00025044
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00092697
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.005971
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00020181
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0020687
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0017335
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.0557e-05
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00022137
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.000517
[32m[1214 21:28:17 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0044392
[32m[1214 21:28:17 @monitor.py:474][0m expreplay/max_score: 12
[32m[1214 21:28:17 @monitor.py:474][0m expreplay/mean_score: 4.0303
[32m[1214 21:28:17 @monitor.py:474][0m huber_loss/value: 0.0044075
[32m[1214 21:28:17 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:28:17 @monitor.py:474][0m param-summary/conv0/W-rms: 0.14633
[32m[1214 21:28:17 @monitor.py:474][0m param-summary/conv1/W-rms: 0.075999
[32m[1214 21:28:17 @monitor.py:474][0m param-summary/conv2/W-rms: 0.068506
[32m[1214 21:28:17 @monitor.py:474][0m param-summary/fc0/W-rms: 0.01678
[32m[1214 21:28:17 @monitor.py:474][0m param-summary/fct/W-rms: 0.080319
[32m[1214 21:28:17 @monitor.py:474][0m predict_reward: -0.1719
[32m[1214 21:28:17 @base.py:273][0m Start Epoch 24 ...
[32m[1214 21:28:57 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:29:38 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:30:18 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:30:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:31:39 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:31:39 @base.py:283][0m Epoch 24 (global_step 600000) finished, time:3 minutes 22 seconds.
[32m[1214 21:31:40 @saver.py:82][0m Model saved to train_log/DQN-pong/model-600000.
[32m[1214 21:31:40 @param.py:161][0m [HyperParamSetter] At global_step=600000, exploration changes from 0.097000 to 0.096769
[32m[1214 21:31:40 @monitor.py:474][0m QueueInput/queue_size: 0.49901
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00060464
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0015285
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0033613
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00023579
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00087197
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0039747
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00018348
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.001845
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0012897
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.8908e-05
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00021149
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00046908
[32m[1214 21:31:40 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0045654
[32m[1214 21:31:40 @monitor.py:474][0m expreplay/max_score: 19
[32m[1214 21:31:40 @monitor.py:474][0m expreplay/mean_score: 10.425
[32m[1214 21:31:40 @monitor.py:474][0m huber_loss/value: 0.0039863
[32m[1214 21:31:40 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:31:40 @monitor.py:474][0m param-summary/conv0/W-rms: 0.14812
[32m[1214 21:31:40 @monitor.py:474][0m param-summary/conv1/W-rms: 0.076521
[32m[1214 21:31:40 @monitor.py:474][0m param-summary/conv2/W-rms: 0.068808
[32m[1214 21:31:40 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016833
[32m[1214 21:31:40 @monitor.py:474][0m param-summary/fct/W-rms: 0.080593
[32m[1214 21:31:40 @monitor.py:474][0m predict_reward: -0.15955
[32m[1214 21:31:40 @base.py:273][0m Start Epoch 25 ...
[32m[1214 21:32:20 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:33:01 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:33:42 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:34:22 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:35:03 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:35:03 @base.py:283][0m Epoch 25 (global_step 625000) finished, time:3 minutes 22 seconds.
[32m[1214 21:35:04 @saver.py:82][0m Model saved to train_log/DQN-pong/model-625000.
[32m[1214 21:35:04 @param.py:161][0m [HyperParamSetter] At global_step=625000, exploration changes from 0.096769 to 0.096538
[32m[1214 21:36:24 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 21:36:24 @monitor.py:474][0m QueueInput/queue_size: 0.75006
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00086029
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0021276
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0037056
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00030328
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0011196
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0053686
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00022488
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0021662
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0021916
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 4.4926e-05
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00024033
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00053
[32m[1214 21:36:24 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0048477
[32m[1214 21:36:24 @monitor.py:474][0m expreplay/max_score: 19
[32m[1214 21:36:24 @monitor.py:474][0m expreplay/mean_score: 8.9429
[32m[1214 21:36:24 @monitor.py:474][0m huber_loss/value: 0.0050995
[32m[1214 21:36:24 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:36:24 @monitor.py:474][0m max_score: 21
[32m[1214 21:36:24 @monitor.py:474][0m mean_score: 19.6
[32m[1214 21:36:24 @monitor.py:474][0m param-summary/conv0/W-rms: 0.14961
[32m[1214 21:36:24 @monitor.py:474][0m param-summary/conv1/W-rms: 0.076973
[32m[1214 21:36:24 @monitor.py:474][0m param-summary/conv2/W-rms: 0.069085
[32m[1214 21:36:24 @monitor.py:474][0m param-summary/fc0/W-rms: 0.01688
[32m[1214 21:36:24 @monitor.py:474][0m param-summary/fct/W-rms: 0.081156
[32m[1214 21:36:24 @monitor.py:474][0m predict_reward: -0.075151
[32m[1214 21:36:24 @group.py:44][0m Callbacks took 81.326 sec in total. PeriodicTrigger-Evaluator: 1 minute 20 seconds
[32m[1214 21:36:24 @base.py:273][0m Start Epoch 26 ...
[32m[1214 21:37:05 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:37:45 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:38:26 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:39:06 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:39:47 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:39:47 @base.py:283][0m Epoch 26 (global_step 650000) finished, time:3 minutes 22 seconds.
[32m[1214 21:39:47 @saver.py:82][0m Model saved to train_log/DQN-pong/model-650000.
[32m[1214 21:39:47 @param.py:161][0m [HyperParamSetter] At global_step=650000, exploration changes from 0.096538 to 0.096308
[32m[1214 21:39:47 @monitor.py:474][0m QueueInput/queue_size: 0.045886
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00052036
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0013034
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0030738
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00020661
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00078085
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0045037
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00016392
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0016476
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0016484
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.3205e-05
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00017244
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00037309
[32m[1214 21:39:47 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0035095
[32m[1214 21:39:47 @monitor.py:474][0m expreplay/max_score: 19
[32m[1214 21:39:47 @monitor.py:474][0m expreplay/mean_score: 14
[32m[1214 21:39:47 @monitor.py:474][0m huber_loss/value: 0.0024575
[32m[1214 21:39:47 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:39:47 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15097
[32m[1214 21:39:47 @monitor.py:474][0m param-summary/conv1/W-rms: 0.077381
[32m[1214 21:39:47 @monitor.py:474][0m param-summary/conv2/W-rms: 0.06933
[32m[1214 21:39:47 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016924
[32m[1214 21:39:47 @monitor.py:474][0m param-summary/fct/W-rms: 0.081573
[32m[1214 21:39:47 @monitor.py:474][0m predict_reward: -0.044074
[32m[1214 21:39:47 @base.py:273][0m Start Epoch 27 ...
[32m[1214 21:40:27 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:41:08 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:41:48 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:42:29 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:43:09 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:43:09 @base.py:283][0m Epoch 27 (global_step 675000) finished, time:3 minutes 22 seconds.
[32m[1214 21:43:10 @saver.py:82][0m Model saved to train_log/DQN-pong/model-675000.
[32m[1214 21:43:10 @param.py:161][0m [HyperParamSetter] At global_step=675000, exploration changes from 0.096308 to 0.096077
[32m[1214 21:43:10 @monitor.py:474][0m QueueInput/queue_size: 0.99632
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00042953
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0010594
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0026795
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00017689
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00064922
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0033035
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00013565
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0013965
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0012882
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.846e-05
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00014622
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00036031
[32m[1214 21:43:10 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0032848
[32m[1214 21:43:10 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 21:43:10 @monitor.py:474][0m expreplay/mean_score: 14.293
[32m[1214 21:43:10 @monitor.py:474][0m huber_loss/value: 0.0021602
[32m[1214 21:43:10 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:43:10 @monitor.py:474][0m param-summary/conv0/W-rms: 0.1521
[32m[1214 21:43:10 @monitor.py:474][0m param-summary/conv1/W-rms: 0.077729
[32m[1214 21:43:10 @monitor.py:474][0m param-summary/conv2/W-rms: 0.069555
[32m[1214 21:43:10 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016961
[32m[1214 21:43:10 @monitor.py:474][0m param-summary/fct/W-rms: 0.082045
[32m[1214 21:43:10 @monitor.py:474][0m predict_reward: 0.033593
[32m[1214 21:43:10 @base.py:273][0m Start Epoch 28 ...
[32m[1214 21:43:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:44:30 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:45:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:45:51 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:46:32 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:46:32 @base.py:283][0m Epoch 28 (global_step 700000) finished, time:3 minutes 21 seconds.
[32m[1214 21:46:33 @saver.py:82][0m Model saved to train_log/DQN-pong/model-700000.
[32m[1214 21:46:33 @param.py:161][0m [HyperParamSetter] At global_step=700000, exploration changes from 0.096077 to 0.095846
[32m[1214 21:46:33 @monitor.py:474][0m QueueInput/queue_size: 0.38574
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00044029
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0010912
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0033368
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00019782
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00071715
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0031588
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00015637
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0014414
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0017575
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.1468e-05
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00015862
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00036615
[32m[1214 21:46:33 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0032265
[32m[1214 21:46:33 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 21:46:33 @monitor.py:474][0m expreplay/mean_score: 13.634
[32m[1214 21:46:33 @monitor.py:474][0m huber_loss/value: 0.0020126
[32m[1214 21:46:33 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:46:33 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15303
[32m[1214 21:46:33 @monitor.py:474][0m param-summary/conv1/W-rms: 0.078031
[32m[1214 21:46:33 @monitor.py:474][0m param-summary/conv2/W-rms: 0.06976
[32m[1214 21:46:33 @monitor.py:474][0m param-summary/fc0/W-rms: 0.016994
[32m[1214 21:46:33 @monitor.py:474][0m param-summary/fct/W-rms: 0.082764
[32m[1214 21:46:33 @monitor.py:474][0m predict_reward: 0.098032
[32m[1214 21:46:33 @base.py:273][0m Start Epoch 29 ...
[32m[1214 21:47:13 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:47:53 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:48:34 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:49:15 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:49:56 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:49:56 @base.py:283][0m Epoch 29 (global_step 725000) finished, time:3 minutes 23 seconds.
[32m[1214 21:49:57 @saver.py:82][0m Model saved to train_log/DQN-pong/model-725000.
[32m[1214 21:49:57 @param.py:161][0m [HyperParamSetter] At global_step=725000, exploration changes from 0.095846 to 0.095615
[32m[1214 21:49:57 @monitor.py:474][0m QueueInput/queue_size: 0.43741
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00052788
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0013024
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0027712
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00021546
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00073862
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0047571
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00016915
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0015897
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.001582
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.4668e-05
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00016204
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00041842
[32m[1214 21:49:57 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0035508
[32m[1214 21:49:57 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 21:49:57 @monitor.py:474][0m expreplay/mean_score: 14.953
[32m[1214 21:49:57 @monitor.py:474][0m huber_loss/value: 0.0024486
[32m[1214 21:49:57 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:49:57 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15409
[32m[1214 21:49:57 @monitor.py:474][0m param-summary/conv1/W-rms: 0.078391
[32m[1214 21:49:57 @monitor.py:474][0m param-summary/conv2/W-rms: 0.070014
[32m[1214 21:49:57 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017031
[32m[1214 21:49:57 @monitor.py:474][0m param-summary/fct/W-rms: 0.083761
[32m[1214 21:49:57 @monitor.py:474][0m predict_reward: 0.16515
[32m[1214 21:49:57 @base.py:273][0m Start Epoch 30 ...
[32m[1214 21:50:37 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:51:17 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:51:57 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:52:38 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:53:18 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:53:18 @base.py:283][0m Epoch 30 (global_step 750000) finished, time:3 minutes 21 seconds.
[32m[1214 21:53:19 @saver.py:82][0m Model saved to train_log/DQN-pong/model-750000.
[32m[1214 21:53:19 @param.py:161][0m [HyperParamSetter] At global_step=750000, exploration changes from 0.095615 to 0.095385
[32m[1214 21:54:40 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 21:54:40 @monitor.py:474][0m QueueInput/queue_size: 2.9462
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00038169
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00095262
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0027395
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00016837
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00061699
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0034495
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00013473
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.001324
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0014161
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.0019e-05
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00013953
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00035793
[32m[1214 21:54:40 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0031341
[32m[1214 21:54:40 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 21:54:40 @monitor.py:474][0m expreplay/mean_score: 15.238
[32m[1214 21:54:40 @monitor.py:474][0m huber_loss/value: 0.0020498
[32m[1214 21:54:40 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:54:40 @monitor.py:474][0m max_score: 20
[32m[1214 21:54:40 @monitor.py:474][0m mean_score: 19.64
[32m[1214 21:54:40 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15507
[32m[1214 21:54:40 @monitor.py:474][0m param-summary/conv1/W-rms: 0.078721
[32m[1214 21:54:40 @monitor.py:474][0m param-summary/conv2/W-rms: 0.070243
[32m[1214 21:54:40 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017068
[32m[1214 21:54:40 @monitor.py:474][0m param-summary/fct/W-rms: 0.084558
[32m[1214 21:54:40 @monitor.py:474][0m predict_reward: 0.23177
[32m[1214 21:54:40 @group.py:44][0m Callbacks took 81.867 sec in total. PeriodicTrigger-Evaluator: 1 minute 21 seconds
[32m[1214 21:54:40 @base.py:273][0m Start Epoch 31 ...
[32m[1214 21:55:20 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:56:01 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:56:42 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:57:22 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:58:03 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:58:03 @base.py:283][0m Epoch 31 (global_step 775000) finished, time:3 minutes 23 seconds.
[32m[1214 21:58:04 @saver.py:82][0m Model saved to train_log/DQN-pong/model-775000.
[32m[1214 21:58:04 @param.py:161][0m [HyperParamSetter] At global_step=775000, exploration changes from 0.095385 to 0.095154
[32m[1214 21:58:04 @monitor.py:474][0m QueueInput/queue_size: 0.53186
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00042106
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0010301
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0023726
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00017732
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00063505
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0039821
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00014457
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0013637
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0010949
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.0451e-05
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00014175
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00035621
[32m[1214 21:58:04 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0031989
[32m[1214 21:58:04 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 21:58:04 @monitor.py:474][0m expreplay/mean_score: 14.6
[32m[1214 21:58:04 @monitor.py:474][0m huber_loss/value: 0.001907
[32m[1214 21:58:04 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 21:58:04 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15591
[32m[1214 21:58:04 @monitor.py:474][0m param-summary/conv1/W-rms: 0.079
[32m[1214 21:58:04 @monitor.py:474][0m param-summary/conv2/W-rms: 0.07043
[32m[1214 21:58:04 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017102
[32m[1214 21:58:04 @monitor.py:474][0m param-summary/fct/W-rms: 0.085183
[32m[1214 21:58:04 @monitor.py:474][0m predict_reward: 0.25506
[32m[1214 21:58:04 @base.py:273][0m Start Epoch 32 ...
[32m[1214 21:58:44 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 21:59:24 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:00:05 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:00:45 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:01:26 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:01:26 @base.py:283][0m Epoch 32 (global_step 800000) finished, time:3 minutes 22 seconds.
[32m[1214 22:01:27 @saver.py:82][0m Model saved to train_log/DQN-pong/model-800000.
[32m[1214 22:01:27 @param.py:161][0m [HyperParamSetter] At global_step=800000, exploration changes from 0.095154 to 0.094923
[32m[1214 22:01:27 @monitor.py:474][0m QueueInput/queue_size: 1.0323
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00038101
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0009456
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0027251
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00015548
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00054842
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0029991
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012739
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011761
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0013624
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.7836e-05
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00012999
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00032804
[32m[1214 22:01:27 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0028226
[32m[1214 22:01:27 @monitor.py:474][0m expreplay/max_score: 19
[32m[1214 22:01:27 @monitor.py:474][0m expreplay/mean_score: 13.513
[32m[1214 22:01:27 @monitor.py:474][0m huber_loss/value: 0.0014593
[32m[1214 22:01:27 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:01:27 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15669
[32m[1214 22:01:27 @monitor.py:474][0m param-summary/conv1/W-rms: 0.079249
[32m[1214 22:01:27 @monitor.py:474][0m param-summary/conv2/W-rms: 0.070594
[32m[1214 22:01:27 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017135
[32m[1214 22:01:27 @monitor.py:474][0m param-summary/fct/W-rms: 0.085651
[32m[1214 22:01:27 @monitor.py:474][0m predict_reward: 0.30814
[32m[1214 22:01:27 @base.py:273][0m Start Epoch 33 ...
[32m[1214 22:02:07 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:02:48 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:03:28 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:04:08 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:04:49 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:04:49 @base.py:283][0m Epoch 33 (global_step 825000) finished, time:3 minutes 22 seconds.
[32m[1214 22:04:50 @saver.py:82][0m Model saved to train_log/DQN-pong/model-825000.
[32m[1214 22:04:50 @param.py:161][0m [HyperParamSetter] At global_step=825000, exploration changes from 0.094923 to 0.094692
[32m[1214 22:04:50 @monitor.py:474][0m QueueInput/queue_size: 0.89298
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00040442
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0010178
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0032003
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.0001667
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00058852
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0022211
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00013197
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0012619
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0013593
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.8264e-05
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00012664
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00033436
[32m[1214 22:04:50 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.002626
[32m[1214 22:04:50 @monitor.py:474][0m expreplay/max_score: 19
[32m[1214 22:04:50 @monitor.py:474][0m expreplay/mean_score: 14.31
[32m[1214 22:04:50 @monitor.py:474][0m huber_loss/value: 0.0015727
[32m[1214 22:04:50 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:04:50 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15732
[32m[1214 22:04:50 @monitor.py:474][0m param-summary/conv1/W-rms: 0.079445
[32m[1214 22:04:50 @monitor.py:474][0m param-summary/conv2/W-rms: 0.070722
[32m[1214 22:04:50 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017163
[32m[1214 22:04:50 @monitor.py:474][0m param-summary/fct/W-rms: 0.086001
[32m[1214 22:04:50 @monitor.py:474][0m predict_reward: 0.37212
[32m[1214 22:04:50 @base.py:273][0m Start Epoch 34 ...
[32m[1214 22:05:30 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:06:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:06:51 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:07:32 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:08:13 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:08:13 @base.py:283][0m Epoch 34 (global_step 850000) finished, time:3 minutes 22 seconds.
[32m[1214 22:08:13 @saver.py:82][0m Model saved to train_log/DQN-pong/model-850000.
[32m[1214 22:08:13 @param.py:161][0m [HyperParamSetter] At global_step=850000, exploration changes from 0.094692 to 0.094462
[32m[1214 22:08:13 @monitor.py:474][0m QueueInput/queue_size: 0.45117
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00037372
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00090265
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0031749
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00015956
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0005602
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0032958
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012877
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0012593
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0011463
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.7435e-05
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.0001233
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00034289
[32m[1214 22:08:13 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0025362
[32m[1214 22:08:13 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:08:13 @monitor.py:474][0m expreplay/mean_score: 15.209
[32m[1214 22:08:13 @monitor.py:474][0m huber_loss/value: 0.0015819
[32m[1214 22:08:13 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:08:13 @monitor.py:474][0m param-summary/conv0/W-rms: 0.158
[32m[1214 22:08:13 @monitor.py:474][0m param-summary/conv1/W-rms: 0.079675
[32m[1214 22:08:13 @monitor.py:474][0m param-summary/conv2/W-rms: 0.070884
[32m[1214 22:08:13 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017193
[32m[1214 22:08:13 @monitor.py:474][0m param-summary/fct/W-rms: 0.086613
[32m[1214 22:08:13 @monitor.py:474][0m predict_reward: 0.38443
[32m[1214 22:08:13 @base.py:273][0m Start Epoch 35 ...
[32m[1214 22:08:53 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:09:34 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:10:15 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:10:55 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:11:36 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:11:36 @base.py:283][0m Epoch 35 (global_step 875000) finished, time:3 minutes 22 seconds.
[32m[1214 22:11:37 @saver.py:82][0m Model saved to train_log/DQN-pong/model-875000.
[32m[1214 22:11:37 @param.py:161][0m [HyperParamSetter] At global_step=875000, exploration changes from 0.094462 to 0.094231
[32m[1214 22:12:55 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 22:12:55 @monitor.py:474][0m QueueInput/queue_size: 0.039549
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00046706
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0012025
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0027569
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00018938
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0006606
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0034318
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00015375
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0013961
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0018407
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.2203e-05
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00014358
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00040758
[32m[1214 22:12:55 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0031381
[32m[1214 22:12:55 @monitor.py:474][0m expreplay/max_score: 19
[32m[1214 22:12:55 @monitor.py:474][0m expreplay/mean_score: 14.524
[32m[1214 22:12:55 @monitor.py:474][0m huber_loss/value: 0.0018564
[32m[1214 22:12:55 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:12:55 @monitor.py:474][0m max_score: 21
[32m[1214 22:12:55 @monitor.py:474][0m mean_score: 20.06
[32m[1214 22:12:55 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15873
[32m[1214 22:12:55 @monitor.py:474][0m param-summary/conv1/W-rms: 0.079931
[32m[1214 22:12:55 @monitor.py:474][0m param-summary/conv2/W-rms: 0.071068
[32m[1214 22:12:55 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017225
[32m[1214 22:12:55 @monitor.py:474][0m param-summary/fct/W-rms: 0.087414
[32m[1214 22:12:55 @monitor.py:474][0m predict_reward: 0.45741
[32m[1214 22:12:55 @group.py:44][0m Callbacks took 78.829 sec in total. PeriodicTrigger-Evaluator: 1 minute 18 seconds
[32m[1214 22:12:55 @base.py:273][0m Start Epoch 36 ...
[32m[1214 22:13:35 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:14:15 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:14:56 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:15:36 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:16:17 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:16:17 @base.py:283][0m Epoch 36 (global_step 900000) finished, time:3 minutes 22 seconds.
[32m[1214 22:16:17 @saver.py:82][0m Model saved to train_log/DQN-pong/model-900000.
[32m[1214 22:16:17 @param.py:161][0m [HyperParamSetter] At global_step=900000, exploration changes from 0.094231 to 0.094000
[32m[1214 22:16:17 @monitor.py:474][0m QueueInput/queue_size: 0.9862
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00046865
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0011745
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0036753
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00020088
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00070692
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0044384
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00015398
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0015001
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0014785
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.3103e-05
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00014985
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00038049
[32m[1214 22:16:17 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0030491
[32m[1214 22:16:17 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:16:17 @monitor.py:474][0m expreplay/mean_score: 15.545
[32m[1214 22:16:17 @monitor.py:474][0m huber_loss/value: 0.0018232
[32m[1214 22:16:17 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:16:17 @monitor.py:474][0m param-summary/conv0/W-rms: 0.15947
[32m[1214 22:16:17 @monitor.py:474][0m param-summary/conv1/W-rms: 0.080178
[32m[1214 22:16:17 @monitor.py:474][0m param-summary/conv2/W-rms: 0.071236
[32m[1214 22:16:17 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017257
[32m[1214 22:16:17 @monitor.py:474][0m param-summary/fct/W-rms: 0.08804
[32m[1214 22:16:17 @monitor.py:474][0m predict_reward: 0.47986
[32m[1214 22:16:17 @base.py:273][0m Start Epoch 37 ...
[32m[1214 22:16:58 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:17:38 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:18:19 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:18:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:19:40 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:19:40 @base.py:283][0m Epoch 37 (global_step 925000) finished, time:3 minutes 22 seconds.
[32m[1214 22:19:41 @saver.py:82][0m Model saved to train_log/DQN-pong/model-925000.
[32m[1214 22:19:41 @param.py:161][0m [HyperParamSetter] At global_step=925000, exploration changes from 0.094000 to 0.093769
[32m[1214 22:19:41 @monitor.py:474][0m QueueInput/queue_size: 2.7421
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00045556
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0011629
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0032986
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00019047
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00066948
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0032652
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00016041
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0014746
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0018276
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.2025e-05
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00014054
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00038651
[32m[1214 22:19:41 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0028987
[32m[1214 22:19:41 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:19:41 @monitor.py:474][0m expreplay/mean_score: 15.978
[32m[1214 22:19:41 @monitor.py:474][0m huber_loss/value: 0.0019307
[32m[1214 22:19:41 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:19:41 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16008
[32m[1214 22:19:41 @monitor.py:474][0m param-summary/conv1/W-rms: 0.080373
[32m[1214 22:19:41 @monitor.py:474][0m param-summary/conv2/W-rms: 0.071362
[32m[1214 22:19:41 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017285
[32m[1214 22:19:41 @monitor.py:474][0m param-summary/fct/W-rms: 0.088307
[32m[1214 22:19:41 @monitor.py:474][0m predict_reward: 0.52921
[32m[1214 22:19:41 @base.py:273][0m Start Epoch 38 ...
[32m[1214 22:20:21 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:21:01 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:21:42 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:22:23 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:23:03 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:23:03 @base.py:283][0m Epoch 38 (global_step 950000) finished, time:3 minutes 22 seconds.
[32m[1214 22:23:04 @saver.py:82][0m Model saved to train_log/DQN-pong/model-950000.
[32m[1214 22:23:04 @param.py:161][0m [HyperParamSetter] At global_step=950000, exploration changes from 0.093769 to 0.093538
[32m[1214 22:23:04 @monitor.py:474][0m QueueInput/queue_size: 0.21873
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00041936
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.001048
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0028278
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00017135
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00062083
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0040639
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00013825
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0013352
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0017912
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.9318e-05
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00013004
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00036485
[32m[1214 22:23:04 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0028669
[32m[1214 22:23:04 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 22:23:04 @monitor.py:474][0m expreplay/mean_score: 15.444
[32m[1214 22:23:04 @monitor.py:474][0m huber_loss/value: 0.0015927
[32m[1214 22:23:04 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:23:04 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16066
[32m[1214 22:23:04 @monitor.py:474][0m param-summary/conv1/W-rms: 0.080567
[32m[1214 22:23:04 @monitor.py:474][0m param-summary/conv2/W-rms: 0.071499
[32m[1214 22:23:04 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017312
[32m[1214 22:23:04 @monitor.py:474][0m param-summary/fct/W-rms: 0.088669
[32m[1214 22:23:04 @monitor.py:474][0m predict_reward: 0.57514
[32m[1214 22:23:04 @base.py:273][0m Start Epoch 39 ...
[32m[1214 22:23:44 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:24:24 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:25:05 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:25:46 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:26:26 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:26:26 @base.py:283][0m Epoch 39 (global_step 975000) finished, time:3 minutes 22 seconds.
[32m[1214 22:26:27 @saver.py:82][0m Model saved to train_log/DQN-pong/model-975000.
[32m[1214 22:26:27 @param.py:161][0m [HyperParamSetter] At global_step=975000, exploration changes from 0.093538 to 0.093308
[32m[1214 22:26:27 @monitor.py:474][0m QueueInput/queue_size: 1.9987
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00044953
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0011081
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0028243
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00019393
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00069312
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0034953
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00015078
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0014998
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0014289
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.1639e-05
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00014439
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00038869
[32m[1214 22:26:27 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.003007
[32m[1214 22:26:27 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:26:27 @monitor.py:474][0m expreplay/mean_score: 15
[32m[1214 22:26:27 @monitor.py:474][0m huber_loss/value: 0.0017262
[32m[1214 22:26:27 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:26:27 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16127
[32m[1214 22:26:27 @monitor.py:474][0m param-summary/conv1/W-rms: 0.080777
[32m[1214 22:26:27 @monitor.py:474][0m param-summary/conv2/W-rms: 0.071643
[32m[1214 22:26:27 @monitor.py:474][0m param-summary/fc0/W-rms: 0.01734
[32m[1214 22:26:27 @monitor.py:474][0m param-summary/fct/W-rms: 0.089128
[32m[1214 22:26:27 @monitor.py:474][0m predict_reward: 0.58053
[32m[1214 22:26:27 @base.py:273][0m Start Epoch 40 ...
[32m[1214 22:27:07 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:27:47 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:28:28 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:29:08 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:29:49 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:29:49 @base.py:283][0m Epoch 40 (global_step 1000000) finished, time:3 minutes 22 seconds.
[32m[1214 22:29:50 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1000000.
[32m[1214 22:29:50 @param.py:161][0m [HyperParamSetter] At global_step=1000000, exploration changes from 0.093308 to 0.093077
[32m[1214 22:31:10 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 22:31:10 @monitor.py:474][0m QueueInput/queue_size: 0.5078
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00035834
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00090211
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0028244
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00014957
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00053771
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0025742
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00011739
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011741
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0011831
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.604e-05
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00011229
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00034578
[32m[1214 22:31:10 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0027358
[32m[1214 22:31:10 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:31:10 @monitor.py:474][0m expreplay/mean_score: 15.587
[32m[1214 22:31:10 @monitor.py:474][0m huber_loss/value: 0.0013091
[32m[1214 22:31:10 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:31:10 @monitor.py:474][0m max_score: 21
[32m[1214 22:31:10 @monitor.py:474][0m mean_score: 19.82
[32m[1214 22:31:10 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16188
[32m[1214 22:31:10 @monitor.py:474][0m param-summary/conv1/W-rms: 0.080979
[32m[1214 22:31:10 @monitor.py:474][0m param-summary/conv2/W-rms: 0.07178
[32m[1214 22:31:10 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017368
[32m[1214 22:31:10 @monitor.py:474][0m param-summary/fct/W-rms: 0.089572
[32m[1214 22:31:10 @monitor.py:474][0m predict_reward: 0.60654
[32m[1214 22:31:10 @group.py:44][0m Callbacks took 80.806 sec in total. PeriodicTrigger-Evaluator: 1 minute 20 seconds
[32m[1214 22:31:10 @base.py:273][0m Start Epoch 41 ...
[32m[1214 22:31:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:32:30 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:33:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:33:51 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:34:32 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:34:32 @base.py:283][0m Epoch 41 (global_step 1025000) finished, time:3 minutes 22 seconds.
[32m[1214 22:34:33 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1025000.
[32m[1214 22:34:33 @param.py:161][0m [HyperParamSetter] At global_step=1025000, exploration changes from 0.093077 to 0.092846
[32m[1214 22:34:33 @monitor.py:474][0m QueueInput/queue_size: 0.48014
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00038296
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00094438
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0020869
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00016022
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00056571
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0022187
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012464
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011644
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.001259
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.7044e-05
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00011319
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00033066
[32m[1214 22:34:33 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0024065
[32m[1214 22:34:33 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 22:34:33 @monitor.py:474][0m expreplay/mean_score: 15.617
[32m[1214 22:34:33 @monitor.py:474][0m huber_loss/value: 0.0012919
[32m[1214 22:34:33 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:34:33 @monitor.py:474][0m param-summary/conv0/W-rms: 0.1625
[32m[1214 22:34:33 @monitor.py:474][0m param-summary/conv1/W-rms: 0.081184
[32m[1214 22:34:33 @monitor.py:474][0m param-summary/conv2/W-rms: 0.071915
[32m[1214 22:34:33 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017397
[32m[1214 22:34:33 @monitor.py:474][0m param-summary/fct/W-rms: 0.089996
[32m[1214 22:34:33 @monitor.py:474][0m predict_reward: 0.62489
[32m[1214 22:34:33 @base.py:273][0m Start Epoch 42 ...
[32m[1214 22:35:13 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:35:53 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:36:34 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:37:14 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:37:55 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:37:55 @base.py:283][0m Epoch 42 (global_step 1050000) finished, time:3 minutes 21 seconds.
[32m[1214 22:37:55 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1050000.
[32m[1214 22:37:56 @param.py:161][0m [HyperParamSetter] At global_step=1050000, exploration changes from 0.092846 to 0.092615
[32m[1214 22:37:56 @monitor.py:474][0m QueueInput/queue_size: 2.2483
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00038811
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00096993
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0024894
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00015669
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00053904
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0022848
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012428
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0012013
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0015475
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.5575e-05
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00011114
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.0003435
[32m[1214 22:37:56 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0027212
[32m[1214 22:37:56 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:37:56 @monitor.py:474][0m expreplay/mean_score: 16.391
[32m[1214 22:37:56 @monitor.py:474][0m huber_loss/value: 0.0013749
[32m[1214 22:37:56 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:37:56 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16305
[32m[1214 22:37:56 @monitor.py:474][0m param-summary/conv1/W-rms: 0.081373
[32m[1214 22:37:56 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072037
[32m[1214 22:37:56 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017424
[32m[1214 22:37:56 @monitor.py:474][0m param-summary/fct/W-rms: 0.090388
[32m[1214 22:37:56 @monitor.py:474][0m predict_reward: 0.63221
[32m[1214 22:37:56 @base.py:273][0m Start Epoch 43 ...
[32m[1214 22:38:36 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:39:16 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:39:57 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:40:38 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:41:19 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:41:19 @base.py:283][0m Epoch 43 (global_step 1075000) finished, time:3 minutes 23 seconds.
[32m[1214 22:41:19 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1075000.
[32m[1214 22:41:19 @param.py:161][0m [HyperParamSetter] At global_step=1075000, exploration changes from 0.092615 to 0.092385
[32m[1214 22:41:19 @monitor.py:474][0m QueueInput/queue_size: 0.12497
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00035128
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00089696
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0025644
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.0001464
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00051135
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0033933
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00011664
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0010848
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0011775
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.6231e-05
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00010805
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00035745
[32m[1214 22:41:19 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0025081
[32m[1214 22:41:19 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 22:41:19 @monitor.py:474][0m expreplay/mean_score: 15.565
[32m[1214 22:41:19 @monitor.py:474][0m huber_loss/value: 0.0012955
[32m[1214 22:41:19 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:41:19 @monitor.py:474][0m param-summary/conv0/W-rms: 0.1636
[32m[1214 22:41:19 @monitor.py:474][0m param-summary/conv1/W-rms: 0.081554
[32m[1214 22:41:19 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072151
[32m[1214 22:41:19 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017451
[32m[1214 22:41:19 @monitor.py:474][0m param-summary/fct/W-rms: 0.090757
[32m[1214 22:41:19 @monitor.py:474][0m predict_reward: 0.6703
[32m[1214 22:41:19 @base.py:273][0m Start Epoch 44 ...
[32m[1214 22:41:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:42:40 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:43:21 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:44:01 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:44:42 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:44:42 @base.py:283][0m Epoch 44 (global_step 1100000) finished, time:3 minutes 22 seconds.
[32m[1214 22:44:43 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1100000.
[32m[1214 22:44:43 @param.py:161][0m [HyperParamSetter] At global_step=1100000, exploration changes from 0.092385 to 0.092154
[32m[1214 22:44:43 @monitor.py:474][0m QueueInput/queue_size: 1.4803
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00035774
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00090139
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0031637
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00015068
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00053956
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0029226
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00011857
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011641
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0014259
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.7718e-05
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.0001138
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00034966
[32m[1214 22:44:43 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0024423
[32m[1214 22:44:43 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:44:43 @monitor.py:474][0m expreplay/mean_score: 15.391
[32m[1214 22:44:43 @monitor.py:474][0m huber_loss/value: 0.0012016
[32m[1214 22:44:43 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:44:43 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16414
[32m[1214 22:44:43 @monitor.py:474][0m param-summary/conv1/W-rms: 0.08174
[32m[1214 22:44:43 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072273
[32m[1214 22:44:43 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017478
[32m[1214 22:44:43 @monitor.py:474][0m param-summary/fct/W-rms: 0.091215
[32m[1214 22:44:43 @monitor.py:474][0m predict_reward: 0.69375
[32m[1214 22:44:43 @base.py:273][0m Start Epoch 45 ...
[32m[1214 22:45:23 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:46:04 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:46:44 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:47:25 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:48:06 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:48:06 @base.py:283][0m Epoch 45 (global_step 1125000) finished, time:3 minutes 22 seconds.
[32m[1214 22:48:06 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1125000.
[32m[1214 22:48:06 @param.py:161][0m [HyperParamSetter] At global_step=1125000, exploration changes from 0.092154 to 0.091923
[32m[1214 22:49:28 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 22:49:29 @monitor.py:474][0m QueueInput/queue_size: 0.20352
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00036761
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00093547
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.002713
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00015514
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00054917
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0028956
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012261
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011703
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0012227
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.8505e-05
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00011652
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00034575
[32m[1214 22:49:29 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0024976
[32m[1214 22:49:29 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 22:49:29 @monitor.py:474][0m expreplay/mean_score: 15.848
[32m[1214 22:49:29 @monitor.py:474][0m huber_loss/value: 0.0012536
[32m[1214 22:49:29 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:49:29 @monitor.py:474][0m max_score: 21
[32m[1214 22:49:29 @monitor.py:474][0m mean_score: 19.12
[32m[1214 22:49:29 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16461
[32m[1214 22:49:29 @monitor.py:474][0m param-summary/conv1/W-rms: 0.08189
[32m[1214 22:49:29 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072356
[32m[1214 22:49:29 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017503
[32m[1214 22:49:29 @monitor.py:474][0m param-summary/fct/W-rms: 0.091351
[32m[1214 22:49:29 @monitor.py:474][0m predict_reward: 0.74124
[32m[1214 22:49:29 @group.py:44][0m Callbacks took 83.000 sec in total. PeriodicTrigger-Evaluator: 1 minute 22 seconds
[32m[1214 22:49:29 @base.py:273][0m Start Epoch 46 ...
[32m[1214 22:50:09 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:50:49 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:51:29 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:52:10 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:52:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:52:50 @base.py:283][0m Epoch 46 (global_step 1150000) finished, time:3 minutes 21 seconds.
[32m[1214 22:52:51 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1150000.
[32m[1214 22:52:51 @param.py:161][0m [HyperParamSetter] At global_step=1150000, exploration changes from 0.091923 to 0.091692
[32m[1214 22:52:51 @monitor.py:474][0m QueueInput/queue_size: 0.43799
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.000339
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00085253
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0027975
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00014905
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00053946
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0023132
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00011356
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011441
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0011958
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.4734e-05
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00011358
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00033679
[32m[1214 22:52:51 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0026348
[32m[1214 22:52:51 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 22:52:51 @monitor.py:474][0m expreplay/mean_score: 16.978
[32m[1214 22:52:51 @monitor.py:474][0m huber_loss/value: 0.0013464
[32m[1214 22:52:51 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:52:51 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16507
[32m[1214 22:52:51 @monitor.py:474][0m param-summary/conv1/W-rms: 0.082038
[32m[1214 22:52:51 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072443
[32m[1214 22:52:51 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017527
[32m[1214 22:52:51 @monitor.py:474][0m param-summary/fct/W-rms: 0.091551
[32m[1214 22:52:51 @monitor.py:474][0m predict_reward: 0.75392
[32m[1214 22:52:51 @base.py:273][0m Start Epoch 47 ...
[32m[1214 22:53:31 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:54:12 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:54:52 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:55:33 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:56:14 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:56:14 @base.py:283][0m Epoch 47 (global_step 1175000) finished, time:3 minutes 22 seconds.
[32m[1214 22:56:14 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1175000.
[32m[1214 22:56:14 @param.py:161][0m [HyperParamSetter] At global_step=1175000, exploration changes from 0.091692 to 0.091462
[32m[1214 22:56:14 @monitor.py:474][0m QueueInput/queue_size: 0.3684
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00037355
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00093641
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0024253
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.000171
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00062413
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0030116
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012433
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0012072
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0011075
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.8943e-05
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00012325
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00036919
[32m[1214 22:56:14 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0027047
[32m[1214 22:56:14 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 22:56:14 @monitor.py:474][0m expreplay/mean_score: 15.467
[32m[1214 22:56:14 @monitor.py:474][0m huber_loss/value: 0.0015211
[32m[1214 22:56:14 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:56:14 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16559
[32m[1214 22:56:14 @monitor.py:474][0m param-summary/conv1/W-rms: 0.082215
[32m[1214 22:56:14 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072557
[32m[1214 22:56:14 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017553
[32m[1214 22:56:14 @monitor.py:474][0m param-summary/fct/W-rms: 0.09192
[32m[1214 22:56:14 @monitor.py:474][0m predict_reward: 0.76982
[32m[1214 22:56:14 @base.py:273][0m Start Epoch 48 ...
[32m[1214 22:56:55 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:57:35 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:58:16 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:58:56 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:59:37 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 22:59:37 @base.py:283][0m Epoch 48 (global_step 1200000) finished, time:3 minutes 22 seconds.
[32m[1214 22:59:38 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1200000.
[32m[1214 22:59:38 @param.py:161][0m [HyperParamSetter] At global_step=1200000, exploration changes from 0.091462 to 0.091231
[32m[1214 22:59:38 @monitor.py:474][0m QueueInput/queue_size: 0.061703
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00037423
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00092141
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0029332
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00016232
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00055533
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0032963
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012631
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011835
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0011835
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.8268e-05
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00011805
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00038693
[32m[1214 22:59:38 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0027349
[32m[1214 22:59:38 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 22:59:38 @monitor.py:474][0m expreplay/mean_score: 16.089
[32m[1214 22:59:38 @monitor.py:474][0m huber_loss/value: 0.0013393
[32m[1214 22:59:38 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 22:59:38 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16615
[32m[1214 22:59:38 @monitor.py:474][0m param-summary/conv1/W-rms: 0.082409
[32m[1214 22:59:38 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072679
[32m[1214 22:59:38 @monitor.py:474][0m param-summary/fc0/W-rms: 0.01758
[32m[1214 22:59:38 @monitor.py:474][0m param-summary/fct/W-rms: 0.092351
[32m[1214 22:59:38 @monitor.py:474][0m predict_reward: 0.81076
[32m[1214 22:59:38 @base.py:273][0m Start Epoch 49 ...
[32m[1214 23:00:18 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:00:59 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:01:39 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:02:20 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:03:00 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:03:00 @base.py:283][0m Epoch 49 (global_step 1225000) finished, time:3 minutes 22 seconds.
[32m[1214 23:03:01 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1225000.
[32m[1214 23:03:01 @param.py:161][0m [HyperParamSetter] At global_step=1225000, exploration changes from 0.091231 to 0.091000
[32m[1214 23:03:01 @monitor.py:474][0m QueueInput/queue_size: 0.49709
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00035327
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0008764
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0020465
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00015409
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00053874
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0031689
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00012006
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011255
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.000792
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.6498e-05
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00010756
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00036156
[32m[1214 23:03:01 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0025976
[32m[1214 23:03:01 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 23:03:01 @monitor.py:474][0m expreplay/mean_score: 16.553
[32m[1214 23:03:01 @monitor.py:474][0m huber_loss/value: 0.0012527
[32m[1214 23:03:01 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 23:03:01 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16674
[32m[1214 23:03:01 @monitor.py:474][0m param-summary/conv1/W-rms: 0.082605
[32m[1214 23:03:01 @monitor.py:474][0m param-summary/conv2/W-rms: 0.0728
[32m[1214 23:03:01 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017607
[32m[1214 23:03:01 @monitor.py:474][0m param-summary/fct/W-rms: 0.092714
[32m[1214 23:03:01 @monitor.py:474][0m predict_reward: 0.83917
[32m[1214 23:03:01 @base.py:273][0m Start Epoch 50 ...
[32m[1214 23:03:41 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:04:22 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:05:03 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:05:43 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:06:24 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:06:24 @base.py:283][0m Epoch 50 (global_step 1250000) finished, time:3 minutes 22 seconds.
[32m[1214 23:06:24 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1250000.
[32m[1214 23:06:24 @param.py:161][0m [HyperParamSetter] At global_step=1250000, exploration changes from 0.091000 to 0.090769
[32m[1214 23:07:44 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 23:07:44 @monitor.py:474][0m QueueInput/queue_size: 0.49615
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00045822
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0011512
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0031927
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00018811
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00065175
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0044665
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00014534
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0013386
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0010508
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.195e-05
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00013612
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00039867
[32m[1214 23:07:44 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0028323
[32m[1214 23:07:44 @monitor.py:474][0m expreplay/max_score: 20
[32m[1214 23:07:44 @monitor.py:474][0m expreplay/mean_score: 16.596
[32m[1214 23:07:44 @monitor.py:474][0m huber_loss/value: 0.0016283
[32m[1214 23:07:44 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 23:07:44 @monitor.py:474][0m max_score: 21
[32m[1214 23:07:44 @monitor.py:474][0m mean_score: 20.3
[32m[1214 23:07:44 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16737
[32m[1214 23:07:44 @monitor.py:474][0m param-summary/conv1/W-rms: 0.082823
[32m[1214 23:07:44 @monitor.py:474][0m param-summary/conv2/W-rms: 0.072939
[32m[1214 23:07:44 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017636
[32m[1214 23:07:44 @monitor.py:474][0m param-summary/fct/W-rms: 0.093207
[32m[1214 23:07:44 @monitor.py:474][0m predict_reward: 0.8547
[32m[1214 23:07:44 @group.py:44][0m Callbacks took 80.207 sec in total. PeriodicTrigger-Evaluator: 1 minute 19 seconds
[32m[1214 23:07:44 @base.py:273][0m Start Epoch 51 ...
[32m[1214 23:08:24 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:09:05 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:09:45 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:10:26 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:11:06 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:11:06 @base.py:283][0m Epoch 51 (global_step 1275000) finished, time:3 minutes 22 seconds.
[32m[1214 23:11:07 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1275000.
[32m[1214 23:11:07 @param.py:161][0m [HyperParamSetter] At global_step=1275000, exploration changes from 0.090769 to 0.090538
[32m[1214 23:11:07 @monitor.py:474][0m QueueInput/queue_size: 0.17334
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00046147
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0011541
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0027631
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00019691
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.0006699
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0040124
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00014593
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0013611
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0012356
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.1881e-05
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00013141
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00038366
[32m[1214 23:11:07 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0027504
[32m[1214 23:11:07 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 23:11:07 @monitor.py:474][0m expreplay/mean_score: 16.089
[32m[1214 23:11:07 @monitor.py:474][0m huber_loss/value: 0.0015804
[32m[1214 23:11:07 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 23:11:07 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16802
[32m[1214 23:11:07 @monitor.py:474][0m param-summary/conv1/W-rms: 0.083052
[32m[1214 23:11:07 @monitor.py:474][0m param-summary/conv2/W-rms: 0.073081
[32m[1214 23:11:07 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017667
[32m[1214 23:11:07 @monitor.py:474][0m param-summary/fct/W-rms: 0.09369
[32m[1214 23:11:07 @monitor.py:474][0m predict_reward: 0.86832
[32m[1214 23:11:07 @base.py:273][0m Start Epoch 52 ...
[32m[1214 23:11:47 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:12:28 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:13:08 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:13:49 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:14:29 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:14:29 @base.py:283][0m Epoch 52 (global_step 1300000) finished, time:3 minutes 22 seconds.
[32m[1214 23:14:30 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1300000.
[32m[1214 23:14:30 @param.py:161][0m [HyperParamSetter] At global_step=1300000, exploration changes from 0.090538 to 0.090308
[32m[1214 23:14:30 @monitor.py:474][0m QueueInput/queue_size: 1.8046
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00040392
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.001022
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0026699
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00016521
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00058862
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0030946
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00013277
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0012573
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.001223
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 3.1058e-05
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00012626
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00038518
[32m[1214 23:14:30 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0024864
[32m[1214 23:14:30 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 23:14:30 @monitor.py:474][0m expreplay/mean_score: 16.298
[32m[1214 23:14:30 @monitor.py:474][0m huber_loss/value: 0.0015567
[32m[1214 23:14:30 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 23:14:30 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16851
[32m[1214 23:14:30 @monitor.py:474][0m param-summary/conv1/W-rms: 0.083206
[32m[1214 23:14:30 @monitor.py:474][0m param-summary/conv2/W-rms: 0.07316
[32m[1214 23:14:30 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017694
[32m[1214 23:14:30 @monitor.py:474][0m param-summary/fct/W-rms: 0.093717
[32m[1214 23:14:30 @monitor.py:474][0m predict_reward: 0.90237
[32m[1214 23:14:30 @base.py:273][0m Start Epoch 53 ...
[32m[1214 23:15:10 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:15:50 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:16:31 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:17:11 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:17:52 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:17:52 @base.py:283][0m Epoch 53 (global_step 1325000) finished, time:3 minutes 22 seconds.
[32m[1214 23:17:53 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1325000.
[32m[1214 23:17:53 @param.py:161][0m [HyperParamSetter] At global_step=1325000, exploration changes from 0.090308 to 0.090077
[32m[1214 23:17:53 @monitor.py:474][0m QueueInput/queue_size: 0.43053
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00036941
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00089382
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0020835
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00015705
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00053268
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0029107
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00011877
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0010989
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0010532
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.7486e-05
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00010599
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00035893
[32m[1214 23:17:53 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0024631
[32m[1214 23:17:53 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 23:17:53 @monitor.py:474][0m expreplay/mean_score: 16.896
[32m[1214 23:17:53 @monitor.py:474][0m huber_loss/value: 0.0012917
[32m[1214 23:17:53 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 23:17:53 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16894
[32m[1214 23:17:53 @monitor.py:474][0m param-summary/conv1/W-rms: 0.083345
[32m[1214 23:17:53 @monitor.py:474][0m param-summary/conv2/W-rms: 0.073237
[32m[1214 23:17:53 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017717
[32m[1214 23:17:53 @monitor.py:474][0m param-summary/fct/W-rms: 0.093866
[32m[1214 23:17:53 @monitor.py:474][0m predict_reward: 0.89346
[32m[1214 23:17:53 @base.py:273][0m Start Epoch 54 ...
[32m[1214 23:18:33 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:19:13 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:19:54 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:20:34 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:21:15 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:21:15 @base.py:283][0m Epoch 54 (global_step 1350000) finished, time:3 minutes 22 seconds.
[32m[1214 23:21:16 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1350000.
[32m[1214 23:21:16 @param.py:161][0m [HyperParamSetter] At global_step=1350000, exploration changes from 0.090077 to 0.089846
[32m[1214 23:21:16 @monitor.py:474][0m QueueInput/queue_size: 0.49824
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00034278
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.0008693
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0033044
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00014816
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00050582
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0028702
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00011338
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0010973
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0012698
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.6161e-05
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00011193
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.0003576
[32m[1214 23:21:16 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0026775
[32m[1214 23:21:16 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 23:21:16 @monitor.py:474][0m expreplay/mean_score: 16.532
[32m[1214 23:21:16 @monitor.py:474][0m huber_loss/value: 0.0014179
[32m[1214 23:21:16 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 23:21:16 @monitor.py:474][0m param-summary/conv0/W-rms: 0.16944
[32m[1214 23:21:16 @monitor.py:474][0m param-summary/conv1/W-rms: 0.08352
[32m[1214 23:21:16 @monitor.py:474][0m param-summary/conv2/W-rms: 0.073345
[32m[1214 23:21:16 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017741
[32m[1214 23:21:16 @monitor.py:474][0m param-summary/fct/W-rms: 0.094259
[32m[1214 23:21:16 @monitor.py:474][0m predict_reward: 0.91589
[32m[1214 23:21:16 @base.py:273][0m Start Epoch 55 ...
[32m[1214 23:21:56 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:22:36 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:23:17 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:23:58 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:24:39 @graph.py:72][0m Running Op RunOp/update_target_network ...
[32m[1214 23:24:39 @base.py:283][0m Epoch 55 (global_step 1375000) finished, time:3 minutes 22 seconds.
[32m[1214 23:24:39 @saver.py:82][0m Model saved to train_log/DQN-pong/model-1375000.
[32m[1214 23:24:39 @param.py:161][0m [HyperParamSetter] At global_step=1375000, exploration changes from 0.089846 to 0.089615
[32m[1214 23:25:58 @common.py:91][0m Waiting for all the workers to finish the last run...
[32m[1214 23:25:58 @monitor.py:474][0m QueueInput/queue_size: 0.34299
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv0/W/rms: 0.00040326
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv0/b/rms: 0.00099446
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv0/prelu/alpha/rms: 0.0042205
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv1/W/rms: 0.00017203
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv1/b/rms: 0.00057514
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv1/prelu/alpha/rms: 0.0031537
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv2/W/rms: 0.00013264
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv2/b/rms: 0.0011954
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/conv2/prelu/alpha/rms: 0.0012144
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/fc0/W/rms: 2.7672e-05
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/fc0/b/rms: 0.00010951
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/fct/W/rms: 0.00035228
[32m[1214 23:25:58 @monitor.py:474][0m SummaryGradient/fct/b/rms: 0.0025217
[32m[1214 23:25:58 @monitor.py:474][0m expreplay/max_score: 21
[32m[1214 23:25:58 @monitor.py:474][0m expreplay/mean_score: 16.625
[32m[1214 23:25:58 @monitor.py:474][0m huber_loss/value: 0.0013413
[32m[1214 23:25:58 @monitor.py:474][0m learning_rate: 0.001
[32m[1214 23:25:58 @monitor.py:474][0m max_score: 21
[32m[1214 23:25:58 @monitor.py:474][0m mean_score: 20.6
[32m[1214 23:25:58 @monitor.py:474][0m param-summary/conv0/W-rms: 0.17004
[32m[1214 23:25:58 @monitor.py:474][0m param-summary/conv1/W-rms: 0.083729
[32m[1214 23:25:58 @monitor.py:474][0m param-summary/conv2/W-rms: 0.073474
[32m[1214 23:25:58 @monitor.py:474][0m param-summary/fc0/W-rms: 0.017769
[32m[1214 23:25:58 @monitor.py:474][0m param-summary/fct/W-rms: 0.094741
[32m[1214 23:25:58 @monitor.py:474][0m predict_reward: 0.94651
[32m[1214 23:25:58 @group.py:44][0m Callbacks took 79.567 sec in total. PeriodicTrigger-Evaluator: 1 minute 18 seconds
[32m[1214 23:25:58 @base.py:273][0m Start Epoch 56 ...
[32m[1214 23:26:09 @base.py:291][0m Detected Ctrl-C and exiting main loop.
[32m[1214 23:26:09 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread QueueInput/input_queue Exited.
